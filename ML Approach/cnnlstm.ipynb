{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ARP Spoof Detection - ML MODEL**"
      ],
      "metadata": {
        "id": "2Tehm5mrBlBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the CSV file and installing importing dependencies"
      ],
      "metadata": {
        "id": "MvFQoRND85ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c4hp0cOmV8Y",
        "outputId": "85a85ea0-28be-459a-fd5d-9e56523245ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwffTsoVTqxp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, TimeDistributed, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.layers import InputLayer, GRU, BatchNormalization, Conv1D, MaxPooling1D, Bidirectional, Dense, Flatten, PReLU, LSTM, ReLU, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras"
      ],
      "metadata": {
        "id": "G4Wbe2MAn90m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/arpcode.csv')"
      ],
      "metadata": {
        "id": "1TZZtrnJ_G1a"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hh7EMmXDULA",
        "outputId": "f18cf02c-e4f9-4612-cda3-fc03f0a87b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Time                 Source        Destination Protocol  Length  Info\n",
            "0  0.000000  PCSSystemtec_3a:59:87  7e:57:ab:7a:2b:f5      ARP      42     0\n",
            "1  2.001191  PCSSystemtec_3a:59:87  7e:57:ab:7a:2b:f5      ARP      42     0\n",
            "2  4.002254  PCSSystemtec_3a:59:87  7e:57:ab:7a:2b:f5      ARP      42     0\n",
            "3  6.002604  PCSSystemtec_3a:59:87  7e:57:ab:7a:2b:f5      ARP      42     0\n",
            "4  8.003296  PCSSystemtec_3a:59:87  7e:57:ab:7a:2b:f5      ARP      42     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making the Model (Wrapping CNN in Time Distributed Layers using CNN-LSTM Architecture)"
      ],
      "metadata": {
        "id": "Fe_0o_vKBWde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 10\n",
        "window_size = 1\n",
        "feature_count = 3\n",
        "lrcn_model = Sequential()\n",
        "\n",
        "# first convolutional block\n",
        "lrcn_model.add(InputLayer(input_shape=(window_size, feature_count)))\n",
        "lrcn_model.add(Conv1D(filters=32, kernel_size=3, padding='causal', activation='ReLU'))\n",
        "lrcn_model.add(LeakyReLU())\n",
        "lrcn_model.add(MaxPooling1D(pool_size=1))\n",
        "lrcn_model.add(BatchNormalization())\n",
        "\n",
        "#Adding LSTM layers\n",
        "lrcn_model.add(LSTM(30, activation='relu', dropout=0.3))\n",
        "lrcn_model.add(BatchNormalization())\n",
        "\n",
        "# output dense layer\n",
        "lrcn_model.add(Dense(1, activation='sigmoid'))\n",
        "lrcn_model.compile(optimizer='adagrad', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "lrcn_model.summary()"
      ],
      "metadata": {
        "id": "SC1nxn49n3_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e76a1b-b5b4-4264-b284-a80233a851af"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_10 (Conv1D)          (None, 1, 32)             320       \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 1, 32)             0         \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPoolin  (None, 1, 32)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 1, 32)             128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 30)                7560      \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 30)                120       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8159 (31.87 KB)\n",
            "Trainable params: 8035 (31.39 KB)\n",
            "Non-trainable params: 124 (496.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the Dataset into Testing and Training"
      ],
      "metadata": {
        "id": "_l5pSJ89OzAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Time'] = pd.to_datetime(df['Time'], unit='s')\n",
        "\n",
        "df['HourOfDay'] = df['Time'].dt.hour + df['Time'].dt.minute / 60 + df['Time'].dt.second / 3600\n",
        "\n",
        "df['TimeSin'] = np.sin(2 * np.pi * df['HourOfDay']/24.0)\n",
        "df['TimeCos'] = np.cos(2 * np.pi * df['HourOfDay']/24.0)\n",
        "\n",
        "y = df['Info']\n",
        "X = df[['Length', 'TimeSin', 'TimeCos']]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape((2528,1,3))\n",
        "X_test = X_test.reshape((632, 1, 3))\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "c3Fv4HexB_uU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f44252f-9d13-49fe-9b70-8fdf3e2b985a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2528, 1, 3) (632, 1, 3) (2528,) (632,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Testing the data"
      ],
      "metadata": {
        "id": "rddt0CWp9IAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = lrcn_model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqWA9QcHQ1W2",
        "outputId": "2ed7053a-b62a-4c3f-9076-1ad1702bb4c3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 22ms/step - loss: 0.7651 - accuracy: 0.5103 - val_loss: 0.6671 - val_accuracy: 0.9304\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6889 - accuracy: 0.5886 - val_loss: 0.6440 - val_accuracy: 0.9304\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6718 - accuracy: 0.6388 - val_loss: 0.6250 - val_accuracy: 0.9304\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.6460 - accuracy: 0.6808 - val_loss: 0.6076 - val_accuracy: 0.9304\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6401 - accuracy: 0.7037 - val_loss: 0.5912 - val_accuracy: 0.9304\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.6270 - accuracy: 0.7148 - val_loss: 0.5752 - val_accuracy: 0.9304\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.7286 - val_loss: 0.5609 - val_accuracy: 0.9304\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.7354 - val_loss: 0.5465 - val_accuracy: 0.9304\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.7500 - val_loss: 0.5327 - val_accuracy: 0.9304\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6013 - accuracy: 0.7532 - val_loss: 0.5201 - val_accuracy: 0.9304\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5885 - accuracy: 0.7619 - val_loss: 0.5083 - val_accuracy: 0.9304\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7694 - val_loss: 0.4999 - val_accuracy: 0.9304\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5731 - accuracy: 0.7733 - val_loss: 0.4935 - val_accuracy: 0.9161\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5720 - accuracy: 0.7793 - val_loss: 0.4876 - val_accuracy: 0.8576\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5641 - accuracy: 0.7915 - val_loss: 0.4846 - val_accuracy: 0.8639\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5636 - accuracy: 0.7872 - val_loss: 0.4823 - val_accuracy: 0.8576\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5584 - accuracy: 0.7931 - val_loss: 0.4817 - val_accuracy: 0.8592\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5483 - accuracy: 0.8050 - val_loss: 0.4797 - val_accuracy: 0.8544\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.7888 - val_loss: 0.4794 - val_accuracy: 0.8560\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7994 - val_loss: 0.4777 - val_accuracy: 0.8560\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.8046 - val_loss: 0.4776 - val_accuracy: 0.8528\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5445 - accuracy: 0.8014 - val_loss: 0.4771 - val_accuracy: 0.8528\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.8097 - val_loss: 0.4722 - val_accuracy: 0.8560\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.8133 - val_loss: 0.4661 - val_accuracy: 0.8560\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.8157 - val_loss: 0.4683 - val_accuracy: 0.8560\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.8113 - val_loss: 0.4648 - val_accuracy: 0.8560\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5246 - accuracy: 0.8153 - val_loss: 0.4638 - val_accuracy: 0.8560\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.8208 - val_loss: 0.4593 - val_accuracy: 0.8560\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.8054 - val_loss: 0.4546 - val_accuracy: 0.8560\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.8216 - val_loss: 0.4552 - val_accuracy: 0.8544\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5067 - accuracy: 0.8279 - val_loss: 0.4520 - val_accuracy: 0.8544\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.8263 - val_loss: 0.4505 - val_accuracy: 0.8544\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.8220 - val_loss: 0.4487 - val_accuracy: 0.8544\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5037 - accuracy: 0.8248 - val_loss: 0.4453 - val_accuracy: 0.8544\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.8311 - val_loss: 0.4412 - val_accuracy: 0.8544\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.8263 - val_loss: 0.4385 - val_accuracy: 0.8560\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4976 - accuracy: 0.8287 - val_loss: 0.4376 - val_accuracy: 0.8560\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4947 - accuracy: 0.8279 - val_loss: 0.4349 - val_accuracy: 0.8560\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4849 - accuracy: 0.8362 - val_loss: 0.4327 - val_accuracy: 0.8576\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4879 - accuracy: 0.8303 - val_loss: 0.4329 - val_accuracy: 0.8576\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.8370 - val_loss: 0.4305 - val_accuracy: 0.8576\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4807 - accuracy: 0.8319 - val_loss: 0.4271 - val_accuracy: 0.8576\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.8374 - val_loss: 0.4246 - val_accuracy: 0.8576\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.8386 - val_loss: 0.4233 - val_accuracy: 0.8576\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.8418 - val_loss: 0.4195 - val_accuracy: 0.8592\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.8378 - val_loss: 0.4167 - val_accuracy: 0.8592\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.8394 - val_loss: 0.4147 - val_accuracy: 0.8592\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.8410 - val_loss: 0.4128 - val_accuracy: 0.8592\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4647 - accuracy: 0.8517 - val_loss: 0.4118 - val_accuracy: 0.8592\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.8335 - val_loss: 0.4115 - val_accuracy: 0.8576\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4662 - accuracy: 0.8398 - val_loss: 0.4096 - val_accuracy: 0.8592\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4619 - accuracy: 0.8434 - val_loss: 0.4086 - val_accuracy: 0.8592\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4613 - accuracy: 0.8449 - val_loss: 0.4056 - val_accuracy: 0.8592\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.8501 - val_loss: 0.4035 - val_accuracy: 0.8592\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4553 - accuracy: 0.8568 - val_loss: 0.4003 - val_accuracy: 0.8576\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4530 - accuracy: 0.8430 - val_loss: 0.4000 - val_accuracy: 0.8576\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.8461 - val_loss: 0.3989 - val_accuracy: 0.8592\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4499 - accuracy: 0.8485 - val_loss: 0.3969 - val_accuracy: 0.8592\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.8509 - val_loss: 0.3958 - val_accuracy: 0.8576\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4431 - accuracy: 0.8584 - val_loss: 0.3928 - val_accuracy: 0.8576\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4408 - accuracy: 0.8612 - val_loss: 0.3920 - val_accuracy: 0.8576\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.8584 - val_loss: 0.3889 - val_accuracy: 0.8576\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.8619 - val_loss: 0.3885 - val_accuracy: 0.8576\n",
            "Epoch 64/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.8544 - val_loss: 0.3864 - val_accuracy: 0.8576\n",
            "Epoch 65/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8501 - val_loss: 0.3875 - val_accuracy: 0.8576\n",
            "Epoch 66/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.8568 - val_loss: 0.3866 - val_accuracy: 0.8576\n",
            "Epoch 67/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.8540 - val_loss: 0.3842 - val_accuracy: 0.8576\n",
            "Epoch 68/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8536 - val_loss: 0.3808 - val_accuracy: 0.8576\n",
            "Epoch 69/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8651 - val_loss: 0.3790 - val_accuracy: 0.8576\n",
            "Epoch 70/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.8608 - val_loss: 0.3786 - val_accuracy: 0.8576\n",
            "Epoch 71/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.8584 - val_loss: 0.3764 - val_accuracy: 0.8576\n",
            "Epoch 72/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.8608 - val_loss: 0.3742 - val_accuracy: 0.8576\n",
            "Epoch 73/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8623 - val_loss: 0.3721 - val_accuracy: 0.8576\n",
            "Epoch 74/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.8683 - val_loss: 0.3717 - val_accuracy: 0.8576\n",
            "Epoch 75/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8655 - val_loss: 0.3706 - val_accuracy: 0.8576\n",
            "Epoch 76/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.8627 - val_loss: 0.3698 - val_accuracy: 0.8576\n",
            "Epoch 77/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8623 - val_loss: 0.3688 - val_accuracy: 0.8576\n",
            "Epoch 78/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8552 - val_loss: 0.3663 - val_accuracy: 0.8608\n",
            "Epoch 79/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8627 - val_loss: 0.3651 - val_accuracy: 0.8608\n",
            "Epoch 80/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8584 - val_loss: 0.3641 - val_accuracy: 0.8608\n",
            "Epoch 81/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8647 - val_loss: 0.3612 - val_accuracy: 0.8608\n",
            "Epoch 82/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8604 - val_loss: 0.3607 - val_accuracy: 0.8608\n",
            "Epoch 83/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8592 - val_loss: 0.3586 - val_accuracy: 0.8623\n",
            "Epoch 84/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8627 - val_loss: 0.3577 - val_accuracy: 0.8623\n",
            "Epoch 85/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8691 - val_loss: 0.3567 - val_accuracy: 0.8623\n",
            "Epoch 86/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8651 - val_loss: 0.3561 - val_accuracy: 0.8623\n",
            "Epoch 87/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8699 - val_loss: 0.3544 - val_accuracy: 0.8655\n",
            "Epoch 88/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8659 - val_loss: 0.3541 - val_accuracy: 0.8655\n",
            "Epoch 89/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8671 - val_loss: 0.3512 - val_accuracy: 0.8639\n",
            "Epoch 90/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8631 - val_loss: 0.3509 - val_accuracy: 0.8639\n",
            "Epoch 91/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8659 - val_loss: 0.3477 - val_accuracy: 0.8655\n",
            "Epoch 92/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8718 - val_loss: 0.3470 - val_accuracy: 0.8655\n",
            "Epoch 93/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8746 - val_loss: 0.3470 - val_accuracy: 0.8623\n",
            "Epoch 94/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8786 - val_loss: 0.3469 - val_accuracy: 0.8639\n",
            "Epoch 95/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8782 - val_loss: 0.3458 - val_accuracy: 0.8655\n",
            "Epoch 96/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8683 - val_loss: 0.3439 - val_accuracy: 0.8623\n",
            "Epoch 97/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8691 - val_loss: 0.3435 - val_accuracy: 0.8623\n",
            "Epoch 98/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8663 - val_loss: 0.3436 - val_accuracy: 0.8623\n",
            "Epoch 99/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8726 - val_loss: 0.3417 - val_accuracy: 0.8655\n",
            "Epoch 100/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8758 - val_loss: 0.3396 - val_accuracy: 0.8655\n",
            "Epoch 101/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8746 - val_loss: 0.3379 - val_accuracy: 0.8655\n",
            "Epoch 102/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8726 - val_loss: 0.3372 - val_accuracy: 0.8639\n",
            "Epoch 103/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8738 - val_loss: 0.3362 - val_accuracy: 0.8639\n",
            "Epoch 104/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8734 - val_loss: 0.3358 - val_accuracy: 0.8639\n",
            "Epoch 105/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8687 - val_loss: 0.3330 - val_accuracy: 0.8639\n",
            "Epoch 106/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3762 - accuracy: 0.8786 - val_loss: 0.3330 - val_accuracy: 0.8639\n",
            "Epoch 107/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3717 - accuracy: 0.8774 - val_loss: 0.3307 - val_accuracy: 0.8639\n",
            "Epoch 108/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3771 - accuracy: 0.8699 - val_loss: 0.3304 - val_accuracy: 0.8639\n",
            "Epoch 109/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3753 - accuracy: 0.8797 - val_loss: 0.3302 - val_accuracy: 0.8639\n",
            "Epoch 110/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3732 - accuracy: 0.8766 - val_loss: 0.3293 - val_accuracy: 0.8639\n",
            "Epoch 111/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3732 - accuracy: 0.8778 - val_loss: 0.3283 - val_accuracy: 0.8639\n",
            "Epoch 112/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3747 - accuracy: 0.8734 - val_loss: 0.3264 - val_accuracy: 0.8639\n",
            "Epoch 113/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3688 - accuracy: 0.8726 - val_loss: 0.3255 - val_accuracy: 0.8639\n",
            "Epoch 114/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3694 - accuracy: 0.8825 - val_loss: 0.3244 - val_accuracy: 0.8639\n",
            "Epoch 115/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3662 - accuracy: 0.8722 - val_loss: 0.3240 - val_accuracy: 0.8639\n",
            "Epoch 116/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3661 - accuracy: 0.8794 - val_loss: 0.3229 - val_accuracy: 0.8639\n",
            "Epoch 117/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3597 - accuracy: 0.8825 - val_loss: 0.3219 - val_accuracy: 0.8639\n",
            "Epoch 118/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8778 - val_loss: 0.3203 - val_accuracy: 0.8639\n",
            "Epoch 119/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8774 - val_loss: 0.3197 - val_accuracy: 0.8608\n",
            "Epoch 120/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8758 - val_loss: 0.3186 - val_accuracy: 0.8608\n",
            "Epoch 121/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8758 - val_loss: 0.3176 - val_accuracy: 0.8608\n",
            "Epoch 122/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8734 - val_loss: 0.3174 - val_accuracy: 0.8608\n",
            "Epoch 123/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3598 - accuracy: 0.8766 - val_loss: 0.3157 - val_accuracy: 0.8608\n",
            "Epoch 124/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.8797 - val_loss: 0.3150 - val_accuracy: 0.8608\n",
            "Epoch 125/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3512 - accuracy: 0.8853 - val_loss: 0.3150 - val_accuracy: 0.8608\n",
            "Epoch 126/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3591 - accuracy: 0.8726 - val_loss: 0.3133 - val_accuracy: 0.8608\n",
            "Epoch 127/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.8841 - val_loss: 0.3124 - val_accuracy: 0.8608\n",
            "Epoch 128/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3581 - accuracy: 0.8730 - val_loss: 0.3121 - val_accuracy: 0.8608\n",
            "Epoch 129/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3568 - accuracy: 0.8746 - val_loss: 0.3110 - val_accuracy: 0.8608\n",
            "Epoch 130/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8794 - val_loss: 0.3108 - val_accuracy: 0.8608\n",
            "Epoch 131/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3561 - accuracy: 0.8750 - val_loss: 0.3096 - val_accuracy: 0.8608\n",
            "Epoch 132/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3455 - accuracy: 0.8849 - val_loss: 0.3097 - val_accuracy: 0.8608\n",
            "Epoch 133/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8849 - val_loss: 0.3085 - val_accuracy: 0.8608\n",
            "Epoch 134/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8805 - val_loss: 0.3073 - val_accuracy: 0.8623\n",
            "Epoch 135/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8643 - val_loss: 0.3066 - val_accuracy: 0.8623\n",
            "Epoch 136/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8829 - val_loss: 0.3049 - val_accuracy: 0.8623\n",
            "Epoch 137/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8841 - val_loss: 0.3048 - val_accuracy: 0.8608\n",
            "Epoch 138/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8841 - val_loss: 0.3036 - val_accuracy: 0.8623\n",
            "Epoch 139/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3411 - accuracy: 0.8837 - val_loss: 0.3029 - val_accuracy: 0.8608\n",
            "Epoch 140/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8825 - val_loss: 0.3031 - val_accuracy: 0.8623\n",
            "Epoch 141/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8809 - val_loss: 0.3021 - val_accuracy: 0.8623\n",
            "Epoch 142/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3426 - accuracy: 0.8853 - val_loss: 0.3007 - val_accuracy: 0.8592\n",
            "Epoch 143/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8881 - val_loss: 0.2987 - val_accuracy: 0.8592\n",
            "Epoch 144/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8829 - val_loss: 0.2985 - val_accuracy: 0.8592\n",
            "Epoch 145/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3396 - accuracy: 0.8821 - val_loss: 0.2968 - val_accuracy: 0.8592\n",
            "Epoch 146/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3378 - accuracy: 0.8837 - val_loss: 0.2968 - val_accuracy: 0.8592\n",
            "Epoch 147/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3385 - accuracy: 0.8821 - val_loss: 0.2957 - val_accuracy: 0.8592\n",
            "Epoch 148/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3371 - accuracy: 0.8873 - val_loss: 0.2947 - val_accuracy: 0.8576\n",
            "Epoch 149/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8924 - val_loss: 0.2952 - val_accuracy: 0.8592\n",
            "Epoch 150/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3355 - accuracy: 0.8833 - val_loss: 0.2947 - val_accuracy: 0.8592\n",
            "Epoch 151/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3299 - accuracy: 0.8932 - val_loss: 0.2946 - val_accuracy: 0.8592\n",
            "Epoch 152/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8900 - val_loss: 0.2938 - val_accuracy: 0.8592\n",
            "Epoch 153/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8770 - val_loss: 0.2934 - val_accuracy: 0.8592\n",
            "Epoch 154/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8845 - val_loss: 0.2916 - val_accuracy: 0.8592\n",
            "Epoch 155/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3318 - accuracy: 0.8813 - val_loss: 0.2908 - val_accuracy: 0.8592\n",
            "Epoch 156/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3305 - accuracy: 0.8857 - val_loss: 0.2906 - val_accuracy: 0.8592\n",
            "Epoch 157/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3313 - accuracy: 0.8888 - val_loss: 0.2902 - val_accuracy: 0.8592\n",
            "Epoch 158/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8857 - val_loss: 0.2888 - val_accuracy: 0.8592\n",
            "Epoch 159/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3302 - accuracy: 0.8805 - val_loss: 0.2895 - val_accuracy: 0.8592\n",
            "Epoch 160/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3266 - accuracy: 0.8869 - val_loss: 0.2882 - val_accuracy: 0.8592\n",
            "Epoch 161/200\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3288 - accuracy: 0.8797 - val_loss: 0.2876 - val_accuracy: 0.8592\n",
            "Epoch 162/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3315 - accuracy: 0.8726 - val_loss: 0.2867 - val_accuracy: 0.8592\n",
            "Epoch 163/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3275 - accuracy: 0.8786 - val_loss: 0.2863 - val_accuracy: 0.8592\n",
            "Epoch 164/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3245 - accuracy: 0.8841 - val_loss: 0.2848 - val_accuracy: 0.8576\n",
            "Epoch 165/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3245 - accuracy: 0.8786 - val_loss: 0.2845 - val_accuracy: 0.8576\n",
            "Epoch 166/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3233 - accuracy: 0.8857 - val_loss: 0.2834 - val_accuracy: 0.8608\n",
            "Epoch 167/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3223 - accuracy: 0.8888 - val_loss: 0.2828 - val_accuracy: 0.8639\n",
            "Epoch 168/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3209 - accuracy: 0.8908 - val_loss: 0.2821 - val_accuracy: 0.8655\n",
            "Epoch 169/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3255 - accuracy: 0.8857 - val_loss: 0.2819 - val_accuracy: 0.8639\n",
            "Epoch 170/200\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3164 - accuracy: 0.8861 - val_loss: 0.2811 - val_accuracy: 0.8655\n",
            "Epoch 171/200\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3169 - accuracy: 0.8924 - val_loss: 0.2807 - val_accuracy: 0.8608\n",
            "Epoch 172/200\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3158 - accuracy: 0.8916 - val_loss: 0.2807 - val_accuracy: 0.8639\n",
            "Epoch 173/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3168 - accuracy: 0.8869 - val_loss: 0.2801 - val_accuracy: 0.8608\n",
            "Epoch 174/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3171 - accuracy: 0.8825 - val_loss: 0.2793 - val_accuracy: 0.8639\n",
            "Epoch 175/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3192 - accuracy: 0.8841 - val_loss: 0.2786 - val_accuracy: 0.8608\n",
            "Epoch 176/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3194 - accuracy: 0.8742 - val_loss: 0.2782 - val_accuracy: 0.8639\n",
            "Epoch 177/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3140 - accuracy: 0.8912 - val_loss: 0.2769 - val_accuracy: 0.8734\n",
            "Epoch 178/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3127 - accuracy: 0.8908 - val_loss: 0.2767 - val_accuracy: 0.8782\n",
            "Epoch 179/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3131 - accuracy: 0.8896 - val_loss: 0.2758 - val_accuracy: 0.8813\n",
            "Epoch 180/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3086 - accuracy: 0.8956 - val_loss: 0.2749 - val_accuracy: 0.8845\n",
            "Epoch 181/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3094 - accuracy: 0.8904 - val_loss: 0.2753 - val_accuracy: 0.8750\n",
            "Epoch 182/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.8912 - val_loss: 0.2757 - val_accuracy: 0.8718\n",
            "Epoch 183/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3119 - accuracy: 0.8920 - val_loss: 0.2745 - val_accuracy: 0.8766\n",
            "Epoch 184/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3057 - accuracy: 0.8956 - val_loss: 0.2740 - val_accuracy: 0.8718\n",
            "Epoch 185/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.8853 - val_loss: 0.2724 - val_accuracy: 0.8797\n",
            "Epoch 186/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3120 - accuracy: 0.8841 - val_loss: 0.2723 - val_accuracy: 0.8766\n",
            "Epoch 187/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3089 - accuracy: 0.8825 - val_loss: 0.2712 - val_accuracy: 0.8877\n",
            "Epoch 188/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3085 - accuracy: 0.8936 - val_loss: 0.2712 - val_accuracy: 0.8908\n",
            "Epoch 189/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3030 - accuracy: 0.8952 - val_loss: 0.2700 - val_accuracy: 0.8877\n",
            "Epoch 190/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3055 - accuracy: 0.8884 - val_loss: 0.2698 - val_accuracy: 0.8877\n",
            "Epoch 191/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.3056 - accuracy: 0.8888 - val_loss: 0.2694 - val_accuracy: 0.8908\n",
            "Epoch 192/200\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3075 - accuracy: 0.8900 - val_loss: 0.2678 - val_accuracy: 0.9019\n",
            "Epoch 193/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.8940 - val_loss: 0.2682 - val_accuracy: 0.9019\n",
            "Epoch 194/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3042 - accuracy: 0.8881 - val_loss: 0.2680 - val_accuracy: 0.8956\n",
            "Epoch 195/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3044 - accuracy: 0.8908 - val_loss: 0.2677 - val_accuracy: 0.8908\n",
            "Epoch 196/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.8821 - val_loss: 0.2671 - val_accuracy: 0.8987\n",
            "Epoch 197/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.3034 - accuracy: 0.8908 - val_loss: 0.2666 - val_accuracy: 0.8956\n",
            "Epoch 198/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8995 - val_loss: 0.2653 - val_accuracy: 0.9146\n",
            "Epoch 199/200\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.2976 - accuracy: 0.8948 - val_loss: 0.2651 - val_accuracy: 0.9098\n",
            "Epoch 200/200\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8956 - val_loss: 0.2649 - val_accuracy: 0.8956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_preds = lrcn_model(X_test)"
      ],
      "metadata": {
        "id": "PyL3UcR7vb4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model_preds), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEK-Ug-QwF61",
        "outputId": "02870b69-940e-4f3a-a3ba-4b6fe41aa8cc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(632, 632)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in zip(model_preds, y_test):\n",
        "  if y==1:\n",
        "    print(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9PkDhtowL1W",
        "outputId": "b2dd2f77-fe88-48c7-e88a-552782e7b13d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.28170305]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.2264389]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.29738575]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.11445358]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.2858905]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.2914685]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.28292933]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.27509218]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.23596704]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.30708066]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.20760183]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.28070927]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.18611397]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.27509218]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.30373457]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.29308727]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.15655237]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.25217062]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.15981366]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.29565793]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.00789881]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.28699198]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.30708066]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.2315675]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.24429683]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.14115244]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.27278695]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.25217062]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.28015986]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.2886076]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.2493537]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.2315675]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.30485436]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.12252531]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.3009367]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.2998595]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.27452993]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.15831901]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.2465388]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.25498882]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.26358452]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.16696411]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.20417945]], shape=(1, 1), dtype=float32) 1\n",
            "tf.Tensor([[0.29020128]], shape=(1, 1), dtype=float32) 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df[['Length', 'TimeSin', 'TimeCos', 'Info']]\n",
        "a['Info'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBMcCr_mw_0c",
        "outputId": "a7ef256a-6bf8-4556-8dba-71bcb025a92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2894\n",
              "1     266\n",
              "Name: Info, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "woT5ihQIU1U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "clf.fit(X_train_flat, y_train)\n",
        "y_pred = clf.predict(X_test_flat)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\",100*accuracy,\"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOV6DgKtTyvM",
        "outputId": "35cc9c29-3ac1-4806-aee3-64fafd115af7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.93037974683544 %\n"
          ]
        }
      ]
    }
  ]
}